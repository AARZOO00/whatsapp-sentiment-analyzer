# V2.0 Complete Testing Guide
## Comprehensive QA Procedures for WhatsApp Sentiment Analyzer

---

## Quick Start Testing (5 minutes)
For a quick validation that v2.0 is working:

```bash
# 1. Server running?
curl http://localhost:8000/health
# Expected: {"status": "healthy", "version": "2.0.0"}

# 2. Upload a test file
curl -F "file=@sample_chat.txt" http://localhost:8000/analyze
# Expected: {"job_id": "...", "status": "processing"}

# 3. Wait a few seconds, then check results
# Use the job_id from step 2
curl http://localhost:8000/results/{job_id}
# Expected: {"status": "complete", ...}
```

---

## Unit Tests - NLP & Analysis

### Test 1.1: Message Parsing
**File:** `test_parsing.py`

```python
import sys
sys.path.insert(0, '/path/to/whatsapp-sentiment-analyzer')

from backend.main_v2 import detect_message_type, extract_emojis, detect_media_types, normalize_timestamp
from datetime import datetime

def test_message_type_detection():
    """Test message type classification"""
    
    # Test text message
    msg_type, is_media, is_emoji_only, is_link = detect_message_type("Hello world")
    assert msg_type == "text", f"Expected 'text', got '{msg_type}'"
    assert not is_media
    assert not is_emoji_only
    assert not is_link
    print("âœ“ Text message detection")
    
    # Test media
    msg_type, is_media, _, _ = detect_message_type("<Media omitted>")
    assert msg_type == "media" and is_media, "Media detection failed"
    print("âœ“ Media detection")
    
    # Test emoji-only
    msg_type, _, is_emoji_only, _ = detect_message_type("ğŸ˜‚ğŸ˜‚ğŸ˜‚")
    assert msg_type == "emoji_only" and is_emoji_only, "Emoji-only detection failed"
    print("âœ“ Emoji-only detection")
    
    # Test link
    msg_type, _, _, is_link = detect_message_type("Check https://example.com")
    assert msg_type == "link" and is_link, "Link detection failed"
    print("âœ“ Link detection")
    
    # Test document
    msg_type, is_media, _, _ = detect_message_type("presentation.pdf")
    assert msg_type == "document" and is_media, "Document detection failed"
    print("âœ“ Document detection")

def test_emoji_extraction():
    """Test emoji detection"""
    
    # Single emoji
    emojis = extract_emojis("Hello ğŸ˜‚")
    assert "ğŸ˜‚" in emojis, f"Emoji not extracted: {emojis}"
    print("âœ“ Single emoji extraction")
    
    # Multiple emojis
    emojis = extract_emojis("ğŸ˜‚â¤ï¸ğŸ”¥")
    assert len(emojis) == 3, f"Expected 3 emojis, got {len(emojis)}"
    print("âœ“ Multiple emoji extraction")
    
    # No emojis
    emojis = extract_emojis("Hello world")
    assert len(emojis) == 0, f"Expected no emojis, got {emojis}"
    print("âœ“ No emoji handling")

def test_media_detection():
    """Test media type detection"""
    
    media_types, count = detect_media_types("<Media omitted>")
    assert "media" in media_types, "Generic media not detected"
    assert count == 1, f"Expected count 1, got {count}"
    print("âœ“ Generic media detection")
    
    media_types, count = detect_media_types("video file <Media omitted>")
    assert "video" in media_types, "Video not detected"
    print("âœ“ Video media detection")
    
    media_types, count = detect_media_types("document.pdf")
    assert "document" in media_types, "Document not detected"
    print("âœ“ Document detection")

def test_timestamp_normalization():
    """Test timestamp parsing"""
    
    # WhatsApp format: 12/25/2023, 14:30
    ts = normalize_timestamp("12/25/2023, 14:30")
    assert ts is not None, "Failed to parse WhatsApp timestamp"
    assert ts.month == 12 and ts.day == 25, f"Parsed incorrectly: {ts}"
    print("âœ“ WhatsApp timestamp normalization")
    
    # ISO format
    ts = normalize_timestamp("2023-12-25 14:30:00")
    assert ts is not None, "Failed to parse ISO timestamp"
    print("âœ“ ISO timestamp normalization")
    
    # Invalid format should return None
    ts = normalize_timestamp("invalid")
    assert ts is None, "Should return None for invalid timestamp"
    print("âœ“ Invalid timestamp handling")

if __name__ == "__main__":
    print("ğŸ§ª Running Unit Tests...")
    print("\nğŸ“ Message Type Detection:")
    test_message_type_detection()
    print("\nğŸ˜€ Emoji Extraction:")
    test_emoji_extraction()
    print("\nğŸ“¹ Media Detection:")
    test_media_detection()
    print("\nâ° Timestamp Normalization:")
    test_timestamp_normalization()
    print("\nâœ… All unit tests passed!")
```

**Run:**
```bash
python test_parsing.py
```

---

## Integration Tests - API Endpoints

### Test 2.1: File Upload & Analysis
**File:** `test_api_upload.py`

```python
import requests
import time
import json

API_URL = "http://localhost:8000"

def test_upload_and_analyze():
    """Test complete analysis pipeline"""
    
    print("ğŸ§ª Test: File Upload & Analysis")
    
    # Read test chat file
    with open("sample_chat.txt", "r") as f:
        chat_content = f.read()
    
    # Upload
    print("1. Uploading chat file...")
    files = {"file": ("sample_chat.txt", chat_content)}
    response = requests.post(f"{API_URL}/analyze", files=files)
    assert response.status_code == 202, f"Upload failed: {response.status_code}"
    
    job_data = response.json()
    job_id = job_data.get("job_id")
    assert job_id, "No job_id returned"
    print(f"   âœ“ Job created: {job_id}")
    
    # Wait for analysis
    print("2. Waiting for analysis (max 30s)...")
    start = time.time()
    while time.time() - start < 30:
        response = requests.get(f"{API_URL}/job/{job_id}")
        status = response.json().get("status")
        
        if status == "completed":
            print("   âœ“ Analysis completed")
            break
        elif status == "failed":
            error = response.json().get("error_message")
            raise AssertionError(f"Analysis failed: {error}")
        
        time.sleep(1)
    else:
        raise AssertionError("Analysis timeout")
    
    # Verify job metadata
    print("3. Verifying job metadata...")
    response = requests.get(f"{API_URL}/job/{job_id}")
    job = response.json()
    
    assert job["status"] == "completed", "Status should be completed"
    assert job["total_messages"] > 0, "Should have parsed messages"
    assert job["parsed_messages"] > 0, "Should have stored messages"
    print(f"   âœ“ Total messages: {job['total_messages']}")
    print(f"   âœ“ Parsed messages: {job['parsed_messages']}")
    print(f"   âœ“ Overall sentiment: {job.get('overall_sentiment_label')}")
    
    # Verify results
    print("4. Verifying analysis results...")
    response = requests.get(f"{API_URL}/results/{job_id}")
    results = response.json()
    
    assert results["status"] == "complete", "Results should be complete"
    assert "job" in results, "Missing job data"
    assert "statistics" in results, "Missing statistics"
    print("   âœ“ Results available")
    
    print("âœ… Upload & Analysis test passed!\n")
    return job_id

if __name__ == "__main__":
    job_id = test_upload_and_analyze()
    print(f"Job ID for further tests: {job_id}")
```

**Run:**
```bash
python test_api_upload.py
```

### Test 2.2: Message Filtering
**File:** `test_api_filters.py`

```python
import requests

API_URL = "http://localhost:8000"

def test_filters(job_id):
    """Test advanced message filtering"""
    
    print(f"ğŸ§ª Test: Message Filtering (Job: {job_id})")
    
    # Test 1: Basic query
    print("1. Testing basic query...")
    response = requests.get(
        f"{API_URL}/messages",
        params={"job_id": job_id, "limit": 10}
    )
    assert response.status_code == 200, f"Failed: {response.status_code}"
    data = response.json()
    total = data.get("total", 0)
    print(f"   âœ“ Found {total} total messages")
    
    # Test 2: Filter by sender
    print("2. Testing sender filter...")
    response = requests.get(
        f"{API_URL}/messages",
        params={"job_id": job_id, "sender": "Alice", "limit": 10}
    )
    if response.status_code == 200:
        data = response.json()
        print(f"   âœ“ Alice has {data['total']} messages")
    
    # Test 3: Filter by sentiment
    print("3. Testing sentiment filter...")
    response = requests.get(
        f"{API_URL}/messages",
        params={"job_id": job_id, "sentiment": "Positive", "limit": 10}
    )
    if response.status_code == 200:
        data = response.json()
        print(f"   âœ“ Positive messages: {data['total']}")
    
    # Test 4: Filter by date range
    print("4. Testing date range filter...")
    response = requests.get(
        f"{API_URL}/messages",
        params={
            "job_id": job_id,
            "start_date": "2024-01-01",
            "end_date": "2024-12-31",
            "limit": 10
        }
    )
    if response.status_code == 200:
        data = response.json()
        print(f"   âœ“ Messages in 2024: {data['total']}")
    
    # Test 5: Filter by message type
    print("5. Testing message type filter...")
    for msg_type in ["text", "media", "emoji_only", "link"]:
        response = requests.get(
            f"{API_URL}/messages",
            params={"job_id": job_id, "message_type": msg_type, "limit": 100}
        )
        if response.status_code == 200:
            data = response.json()
            print(f"   âœ“ {msg_type}: {data['total']} messages")
    
    # Test 6: Combined filters
    print("6. Testing combined filters...")
    response = requests.get(
        f"{API_URL}/messages",
        params={
            "job_id": job_id,
            "sentiment": "Positive",
            "message_type": "text",
            "limit": 10
        }
    )
    if response.status_code == 200:
        data = response.json()
        print(f"   âœ“ Positive text messages: {data['total']}")
    
    print("âœ… Message filtering tests passed!\n")

if __name__ == "__main__":
    job_id = input("Enter job_id to test: ")
    test_filters(job_id)
```

**Run:**
```bash
python test_api_filters.py
```

### Test 2.3: Analytics Endpoints
**File:** `test_api_analytics.py`

```python
import requests
import json

API_URL = "http://localhost:8000"

def test_analytics(job_id):
    """Test emoji and media analytics"""
    
    print(f"ğŸ§ª Test: Analytics Endpoints (Job: {job_id})")
    
    # Test 1: Statistics
    print("1. Testing /stats endpoint...")
    response = requests.get(f"{API_URL}/stats/{job_id}")
    assert response.status_code == 200, f"Failed: {response.status_code}"
    stats = response.json()
    
    print(f"   âœ“ Total messages: {stats.get('total_messages')}")
    print(f"   âœ“ Unique senders: {stats.get('unique_senders')}")
    print(f"   âœ“ Overall sentiment: {stats.get('overall_sentiment')}")
    
    # Test 2: Emoji Analytics
    print("2. Testing /emoji-stats endpoint...")
    response = requests.get(f"{API_URL}/emoji-stats/{job_id}")
    assert response.status_code == 200, f"Failed: {response.status_code}"
    emojis = response.json()
    
    print(f"   âœ“ Total emojis used: {emojis.get('total_emojis_used')}")
    print(f"   âœ“ Unique emojis: {emojis.get('unique_emojis')}")
    
    if emojis.get('top_emojis'):
        top = emojis['top_emojis'][0]
        print(f"   âœ“ Top emoji: {top.get('emoji_char')} ({top.get('usage_count')} times)")
    
    # Test 3: Media Analytics
    print("3. Testing /media-stats endpoint...")
    response = requests.get(f"{API_URL}/media-stats/{job_id}")
    assert response.status_code == 200, f"Failed: {response.status_code}"
    media = response.json()
    
    print(f"   âœ“ Total media: {media.get('total_media')}")
    if media.get('media_by_type'):
        for mtype, count in media['media_by_type'].items():
            print(f"     - {mtype}: {count}")
    
    print("âœ… Analytics tests passed!\n")

if __name__ == "__main__":
    job_id = input("Enter job_id to test: ")
    test_analytics(job_id)
```

**Run:**
```bash
python test_api_analytics.py
```

### Test 2.4: Job Persistence
**File:** `test_persistence.py`

```python
import requests
import subprocess
import time
import signal
import os

API_URL = "http://localhost:8000"

def test_persistence():
    """Test job persistence across restarts"""
    
    print("ğŸ§ª Test: Job Persistence")
    
    # Step 1: Upload a file
    print("1. Uploading chat file...")
    with open("sample_chat.txt", "r") as f:
        files = {"file": ("sample_chat.txt", f)}
        response = requests.post(f"{API_URL}/analyze", files=files)
    
    job_id = response.json()["job_id"]
    print(f"   âœ“ Job ID: {job_id}")
    
    # Step 2: Wait for analysis
    print("2. Waiting for analysis completion...")
    time.sleep(10)
    
    response = requests.get(f"{API_URL}/job/{job_id}")
    initial_status = response.json().get("status")
    print(f"   âœ“ Status before restart: {initial_status}")
    
    # Step 3: Find and kill server process
    print("3. Stopping server (simulating restart)...")
    os.system("lsof -ti:8000 | xargs kill -9 2>/dev/null || true")
    time.sleep(2)
    print("   âœ“ Server stopped")
    
    # Step 4: Restart server
    print("4. Restarting server...")
    # Note: In real scenario, server auto-restarts
    # For testing, manually run: python -m uvicorn backend.main:app --port 8000
    time.sleep(3)
    
    # Step 5: Check if job still exists
    print("5. Checking job existence after restart...")
    try:
        response = requests.get(f"{API_URL}/job/{job_id}", timeout=5)
        if response.status_code == 200:
            after_status = response.json().get("status")
            print(f"   âœ“ Job found after restart!")
            print(f"   âœ“ Status after restart: {after_status}")
            print(f"   âœ“ Status unchanged: {initial_status == after_status}")
            print("âœ… Persistence test passed!\n")
        else:
            print("âŒ Job not found after restart (persistence failed)")
    except:
        print("âŒ Server not responding - ensure it's restarted")

if __name__ == "__main__":
    print("âš ï¸  This test will stop the server!")
    print("Ensure you can restart it manually or have auto-restart enabled.")
    confirm = input("Continue? (yes/no): ")
    if confirm.lower() == "yes":
        test_persistence()
```

---

## Database Tests

### Test 3.1: Database Integrity
**File:** `test_database.py`

```python
import sqlite3
import sys
sys.path.insert(0, '/path/to/whatsapp-sentiment-analyzer')

from backend.database import init_db, get_job, query_messages_advanced

def test_database():
    """Test database schema and operations"""
    
    print("ğŸ§ª Test: Database Integrity")
    
    # Initialize
    init_db()
    print("âœ“ Database initialized")
    
    # Check tables exist
    conn = sqlite3.connect('backend/chat_analysis.db')
    c = conn.cursor()
    
    c.execute("SELECT name FROM sqlite_master WHERE type='table'")
    tables = [row[0] for row in c.fetchall()]
    
    required_tables = ['jobs_v2', 'messages_v2', 'emoji_analytics', 'media_analytics', 'summaries']
    
    print("\nğŸ“Š Checking tables:")
    for table in required_tables:
        if table in tables:
            c.execute(f"SELECT COUNT(*) FROM {table}")
            count = c.fetchone()[0]
            print(f"   âœ“ {table}: {count} records")
        else:
            print(f"   âŒ {table}: MISSING")
    
    # Check indices
    print("\nğŸ” Checking indices:")
    c.execute("SELECT name FROM sqlite_master WHERE type='index' AND name LIKE 'idx_%'")
    indices = [row[0] for row in c.fetchall()]
    print(f"   âœ“ {len(indices)} indices found")
    
    conn.close()
    print("\nâœ… Database integrity test passed!\n")

if __name__ == "__main__":
    test_database()
```

**Run:**
```bash
python test_database.py
```

---

## Manual Testing Checklist

### Checklist A: Basic Functionality
- [ ] Server starts without errors
- [ ] API docs accessible at `/docs`
- [ ] Health check returns 200: `curl http://localhost:8000/health`
- [ ] Can upload a .txt file
- [ ] Analysis completes within 30 seconds
- [ ] Results show "completed" status

### Checklist B: Message Analysis
- [ ] Messages are parsed correctly
- [ ] Sentiment scores calculated
- [ ] Languages detected
- [ ] Emotions extracted
- [ ] Keywords identified
- [ ] Toxicity flagged

### Checklist C: New Features
- [ ] Message types detected (text/media/emoji_only/link)
- [ ] Emojis extracted and counted
- [ ] Media detected from WhatsApp markers
- [ ] Timestamps normalized
- [ ] User names parsed correctly
- [ ] Sent/Received indicators handled

### Checklist D: Analytics
- [ ] Emoji stats show usage counts
- [ ] Emoji senders tracked
- [ ] Media stats show breakdown
- [ ] Message type distribution calculated
- [ ] Sentiment distribution shown
- [ ] Language stats computed

### Checklist E: Filtering
- [ ] Filter by sender works
- [ ] Filter by date range works
- [ ] Filter by sentiment works
- [ ] Filter by language works
- [ ] Filter by message type works
- [ ] Combined filters work
- [ ] Pagination works

### Checklist F: Persistence
- [ ] Job survives page refresh
- [ ] Job exists after server restart (with manual restart)
- [ ] Results can be retrieved hours later
- [ ] Message details preserved

### Checklist G: Error Handling
- [ ] Invalid file type rejected
- [ ] Empty file rejected
- [ ] Too large file rejected
- [ ] Invalid job_id returns 404
- [ ] Invalid filters handled gracefully
- [ ] Missing required parameters return error

---

## Performance Testing

### Load Test
```bash
#!/bin/bash
# Test with multiple concurrent uploads

echo "ğŸ§ª Load Test: Multiple Concurrent Uploads"

for i in {1..5}; do
    echo "Uploading file $i..."
    curl -F "file=@sample_chat.txt" http://localhost:8000/analyze &
    sleep 0.5
done

wait
echo "âœ… All uploads complete"
```

### Response Time Test
```bash
#!/bin/bash
# Measure response times

echo "â±ï¸ Response Time Test"

# Analyze command
time curl -F "file=@sample_chat.txt" http://localhost:8000/analyze

# Messages query
time curl "http://localhost:8000/messages?job_id=xxx&limit=50"

# Analytics
time curl http://localhost:8000/emoji-stats/xxx
time curl http://localhost:8000/media-stats/xxx
```

---

## API Response Validation

### Sample Responses to Verify

**POST /analyze** (202 Accepted):
```json
{
  "job_id": "123e4567-e89b-12d3-a456-426614174000",
  "status": "processing"
}
```

**GET /job/{job_id}** (200 OK):
```json
{
  "job_id": "...",
  "filename": "sample_chat.txt",
  "status": "completed",
  "total_messages": 250,
  "parsed_messages": 248,
  "failed_messages": 2,
  "overall_sentiment_score": 0.15,
  "overall_sentiment_label": "Positive",
  "processing_time_seconds": 4.23,
  "created_at": "2024-01-15T10:30:00",
  "completed_at": "2024-01-15T10:30:04"
}
```

**GET /messages** (200 OK):
```json
{
  "messages": [
    {
      "message_id": "...",
      "timestamp": "2024-01-15T10:30:00",
      "sender": "Alice",
      "raw_text": "That's amazing! ğŸ˜‚",
      "message_type": "text",
      "sentiment": {
        "ensemble_label": "Positive",
        "ensemble_score": 0.89
      },
      "emoji_list": ["ğŸ˜‚"],
      "media_types": [],
      "is_toxic": false
    }
  ],
  "total": 250,
  "page": 1,
  "limit": 50,
  "total_pages": 5
}
```

**GET /emoji-stats/{job_id}** (200 OK):
```json
{
  "job_id": "...",
  "total_emojis_used": 142,
  "unique_emojis": 23,
  "top_emojis": [
    {
      "emoji_char": "ğŸ˜‚",
      "emoji_name": "face_with_tears_of_joy",
      "emoji_category": "people",
      "usage_count": 35,
      "unique_users": 5,
      "user_list": ["Alice", "Bob"]
    }
  ],
  "user_emoji_preferences": {
    "Alice": ["ğŸ˜‚", "â¤ï¸"],
    "Bob": ["ğŸ˜‚", "ğŸ”¥"]
  }
}
```

---

## Troubleshooting Failed Tests

| Test | Failure | Solution |
|------|---------|----------|
| Upload fails with 400 | File format wrong | Ensure .txt file, UTF-8 encoding |
| Analysis timeout | Server slow | Check logs, increase timeout |
| Filters return 0 | Date format wrong | Use YYYY-MM-DD |
| Emojis show 0 | No emojis in chat | Test with emoji-containing chat |
| Job not found | Wrong job_id | Copy from upload response |
| Database error | Schema missing | Run `init_db()` |

---

## Final Verification

After all tests pass:

```bash
âœ… Unit tests pass
âœ… API tests pass
âœ… Database tests pass
âœ… Analytics endpoints work
âœ… Filtering works
âœ… Persistence works
âœ… Error handling works
âœ… Performance acceptable

=> Ready for production deployment!
```

---

**Testing Complete! ğŸ‰**

All 10 major issues have been addressed and tested.
The v2.0 backend is production-ready.
